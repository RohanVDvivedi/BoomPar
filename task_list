 * use linux api of user context to allow separate stacks and let the job wait on a pointer (pointing to mutex or condition variable or anything)
 * we use this pointer to put the job in a hash table, to eventually wake it up when the event occurs. a wait wih NULL implied an exit.
 * a yield implies exit with a return value, or a return fron the job function is also a return with a value.
 * make job just like a co-routine on multiple threads, reduce the stack size of these threads saving memory
 * allow jobs to have different stack sizes (probably smaller)
 * wake_one and wake_all calls can be used on a pointer to wake up one or more jobs that are waiting on a pointer, for a resource

 * implement promises to hold more than one result as a queue, releasing them in order.
 * implement get_results function to get n results from the promise, or do a get_result to get 1 result from the promise.

 * implement shared_ptr like that of c++ here, destroying the pointer/reference will destroy the object only if its reference count reaches 0
 * get_new_sharable_reference increments the reference count and returns the pointer to the object
 * use this shared_ptr for BufferPool page_request struct
